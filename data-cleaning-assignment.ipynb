{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be88799",
   "metadata": {},
   "source": [
    "# Data Cleaning Assignment\n",
    "\n",
    "For this assignment, you will be practicing your web scraping and data cleaning skills on a website of your choice. \n",
    "\n",
    "Use the code provided to get started, but you will need to input specifics like your chosen URL, and the parts that you need to clean from the results. \n",
    "\n",
    "At the end, I will ask you to briefly reflect on your progress and speculate on next steps for this work (if you were to continue this work). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0290b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, load up the necessary libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6567545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, load up the webpage and create a 'soup' object\n",
    "# be sure to paste your webpage URL in the get() function, as a string \n",
    "\n",
    "webpage = requests.get('')\n",
    "source = webpage.content\n",
    "soup = BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639093c5",
   "metadata": {},
   "source": [
    "## identifying html tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba44a2de",
   "metadata": {},
   "source": [
    "Before you can scrape a specific part of an webpage, you need to find out the html tag for the element you want to scrape. You may need to play around with scraping different elements to find the desired one. \n",
    "\n",
    "\n",
    "Note: if you want to scrape an attribute, check out the bs4 docs on [attributes](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#bs4.Tag.attrs) to get started. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326d465",
   "metadata": {},
   "source": [
    "First, print a slice (maybe the first 10 times) of your new soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5335fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73d04f41",
   "metadata": {},
   "source": [
    "Now, print out the following elements, one by one: a title, a heading, a paragraph and a link. You may need to do some research on the [tags and attributes](\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#bs4.Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e2087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d6c9a26",
   "metadata": {},
   "source": [
    "Now, use some bs4 methods for navigating up and down the object tree, like `.child`, `.parent` and for scraping just the text with `.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fac33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f22c59",
   "metadata": {},
   "source": [
    "## scraping the right tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3f6c4",
   "metadata": {},
   "source": [
    "In the next section, I will provide some code for you to modify in order to scrape the elements you want. \n",
    "\n",
    "In order to find out the element I need to scrape, go the page source. Here, use the \"inspector\" tool. On most browsers, you can fire up this tool by right-clicking on the element you want to scrape. After right-clicking on your desired element that you want to scrape, in the popup menu, select \"inspect.\" Then, a window should appear that covers about half of your webpage. Check in the largest panel in this window (the one displaying html code) and look for the *highlighted code* in this section. That code contains the name of the html tag that you want to scrape.\n",
    "\n",
    "Finally, in the cell below, complete the loop with your desired HTML element in the find_all() function. Remember the element needs to be written as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a for loop that goes through all of the tags in our 'soup' object\n",
    "# then uses the 'text' attribute to grab just the text (taking out the html tag)\n",
    "# for that item\n",
    "\n",
    "for item in soup.find_all(''):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071757f",
   "metadata": {},
   "source": [
    "If you want to weed out items that contain a certain word in the text, use the code in the cell below as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ec493",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# insert the element you want to scrape in find_all()\n",
    "for item in soup.find_all(''):\n",
    "    \n",
    "    # insert the text you want to search for (within this element) between quotes\n",
    "    if '' in item.text:\n",
    "        \n",
    "        # append the text to our new list\n",
    "        results.append(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking our output, just the first item (at position 0)\n",
    "\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc83a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the first 10 items\n",
    "\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab426e54",
   "metadata": {},
   "source": [
    "## cleaning the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed05bca",
   "metadata": {},
   "source": [
    "### the `strip()` function\n",
    "\n",
    "Check the results for things that you may want to remove from your data. For this, we will use the `strip()` function. Some things to removemight include characters, like:\n",
    "- `\\n` characters\n",
    "- `\\n\\n` characters\n",
    "- `\\n\\n\\n` characters\n",
    "\n",
    "### the `split()` function\n",
    "We may also want to separate out part of the resutls from a single string into separate strings, so that they can populate separate cells on a spreadsheet. For this we will use the `split()` function. For example, we may want the following string: \n",
    "\n",
    "`'Abut, Daniel Adjunct Assistant Professor of Finance Finance Department daa249@stern.nyu.edu'`\n",
    "\n",
    "to become a part of a list of individual strings, like: \n",
    "\n",
    "`'Abut, Daniel ', 'Adjunct Assistant Professor of Finance, Finance Department', 'daa249@stern.nyu.edu'`\n",
    "\n",
    "### the `replace()` function\n",
    "\n",
    "Sometimes, you may want to take out something and replace it with a space. For example, if you want to take out a certain character and put in a space. Read more about `replace()` [on RealPython](https://realpython.com/replace-string-python/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a sample loop which you can modify to strip out unwanted elements \n",
    "# from your dataset.\n",
    "\n",
    "stripped = []\n",
    "\n",
    "for item in results:\n",
    "    stripped.append(item.strip(''))\n",
    "    \n",
    "# check the results\n",
    "stripped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c2dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also do the same using 'list comprehension' - a way of shortening\n",
    "# the syntax to compress the loop into one line of code.\n",
    "\n",
    "stripped = [item.strip('') for item in results]\n",
    "\n",
    "# check the first few lines\n",
    "stripped[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d008187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a more complex process that splits the strings in the list if they \n",
    "# happend to have the \\n\\n character. This is useful for creating individual \n",
    "# strings, which will be useful for later creating individual cells on a \n",
    "# spreadsheet\n",
    "\n",
    "# First, the traditional version of loop:\n",
    "\n",
    "divided = []\n",
    "for row in stripped:\n",
    "    for item in row.split('\\n\\n'):\n",
    "        divided.append(item)\n",
    "        \n",
    "# Now, the list comprehension version of the same loop! Look closely to see \n",
    "# the logic is the same, but with compressed syntax. \n",
    "\n",
    "divided_comp = [item for row in stripped for item in row.split('\\n\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c119b",
   "metadata": {},
   "source": [
    "## Reflection: \n",
    "In the markdown cell below, explain your work on this assignment. What did you decide to scrape from the website? How did the work go? Is there anything you didn't know how to do or any obstacles you encountered? How did you handle the obstacles? (And it's totally fine to say you were discouraged and/or gave up!! Coding is really hard) Reflect a bit on your original objective and current progress.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036c12c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ea8299",
   "metadata": {},
   "source": [
    "## OPTIONAL: writing CSV to format and save our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14968343",
   "metadata": {},
   "source": [
    "This section is completely optional, because not every \n",
    "Alter the relevant code below to transfer your data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a102be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want a format where it's just *one* item per row, adopt the code \n",
    "# below with your information \n",
    "\n",
    "import csv\n",
    "    \n",
    "story_wrappers = soup.find_all(class_ = 'story-wrapper')\n",
    "    \n",
    "for item in story_wrappers:\n",
    "    link_text = item.a.text\n",
    "    print(link_text)\n",
    "    \n",
    "    link_location = item.a['href']\n",
    "    print(link_location)\n",
    "\n",
    "    csv_writer.writerow([link_text, link_location])\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be1c582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want *multiple* items per row (if you happen to be scraping tabular data),\n",
    "# adapt the code below\n",
    "\n",
    "import csv\n",
    "\n",
    "# open output files and call up the data\n",
    "with open('adjuncts.csv', 'w', newline='') as output_file:\n",
    "    # create csv reader and writer objects\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # iterate over rows in our data\n",
    "    for cell in divided:\n",
    "        # check if cell contains \"edu\"\n",
    "        if \"edu\" in cell:\n",
    "            # add cell to new row and write to output file\n",
    "            new_row.append(cell)\n",
    "            writer.writerow(new_row)\n",
    "            # start new row\n",
    "            new_row = []\n",
    "        else:\n",
    "            # add cell to current row\n",
    "            new_row.append(cell)\n",
    "    # write last row to output file\n",
    "    writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

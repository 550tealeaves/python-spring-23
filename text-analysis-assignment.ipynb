{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text analysis assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this text analysis assignment, you will do a text analysis of a text and write up a paragraph about your results. Choose from one of the two options below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 1:\n",
    "\n",
    "First, choose a text for your analysis. It needs to be in `.txt` format. You might check the [Project Gutenberg](https://www.gutenberg.org/) website for options. \n",
    "\n",
    "Second, you will first load and clean the text using the code below and other code from class or your own research. \n",
    "\n",
    "Then, use some [NLTK methods](https://www.nltk.org/api/nltk.text.html) for analysis. For example, you might use `similar()`, `concordance()`, `distribution_plot([])`, `collocations()`, and `common_contexts([])`. You can check word counts with with `text.vocab().most_common(20)` \n",
    "\n",
    "Finally, you will write up a paragraph about your results and propose (if any) further directions for research. In your response, try to answer the following questions:\n",
    "   - What did you discover about your topic? What patterns emerged from the analysis? \n",
    "   - Based on your exploration so far, what kind of further questions could you ask about the topic or data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 2:\n",
    "\n",
    "If you do not have a a text in mind, you can choose from one of the below prompts instead: \n",
    "\n",
    "- Text analysis of **gender** from texts in nltk.book.\n",
    "- Text analysis of **monsters** from texts in nltk.book\n",
    "\n",
    "If you choose **genders**, do the following:\n",
    "- Load up nltk.book. Choose one text by a man and one text by a woman.\n",
    "- Load and clean the text using the functions defined in the `nltk: text analysis` class notes.\n",
    "- Do some text analysis using at least four NLTK methods like:\n",
    "    - `similar()`, `concordance()`, `distribution_plot([])`, `collocations()`, and `common_contexts([])`\n",
    "    - check word counts with `text.vocab().most_common(20)` \n",
    "- Write a paragraph (5 - 7 sentences) about your results, and answer the following questions:\n",
    "   - What did you discover about the way gender is portrayed across the two texts? \n",
    "   - Based on your exploration so far, what kind of further questions could you ask about the topic or data?\n",
    "\n",
    "If you choose **monsters**, do the following:\n",
    "- Load up nltk.book. Select two texts, *Dracula* and *Frankenstein*.\n",
    "- Load and clean the text using the functions defined in the `nltk: text analysis` class notes.\n",
    "- Do some text analysis using at least four NLTK methods like:\n",
    "    - `similar()`, `concordance()`, `distribution_plot([])`, `collocations()`, and `common_contexts([])`\n",
    "    - check word counts with `text.vocab().most_common(20)` \n",
    "- Write a paragraph (5 - 7 sentences) about your results, and answer the following questions:\n",
    "   - What did you discover about the way monsters are portrayed across the two texts? \n",
    "   - Based on your exploration so far, what kind of further questions could you ask about the topic or data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading and cleaning\n",
    "below this cell, select and clean your texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use all/part of this function to load and clean your text\n",
    "\n",
    "def clean(url):\n",
    "    stops = stopwords.words('english')\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    open_url = urlopen(url)\n",
    "    read_text = open_url.read()\n",
    "    decoded_text = read_text.decode()\n",
    "    tokens = nltk.word_tokenize(decoded_text)\n",
    "    \n",
    "    text = [] \n",
    "    for word in tokens:\n",
    "        if word.isalpha(): \n",
    "            if word not in stops:\n",
    "                lemma = wordnet_lemmatizer.lemmatize(word)\n",
    "                text.append(word.lower())     \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## text analysis with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## paragraph on your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
